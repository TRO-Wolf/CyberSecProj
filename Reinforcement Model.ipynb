{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6751818b",
   "metadata": {},
   "source": [
    "# Increasing the Notebook Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9235385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c96dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Native Python Libraries\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import argparse\n",
    "import collections\n",
    "import re\n",
    "from collections import namedtuple, deque, defaultdict\n",
    "from itertools import count\n",
    "\n",
    "# Importing Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "\n",
    "# Importing Matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing TA-Lib\n",
    "import talib\n",
    "\n",
    "# import PyTorch LIbraries\n",
    "import torch\n",
    "import torch.utils.data as utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Importing SciKit Learn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, scale\n",
    "\n",
    "# Importing RL Libraries\n",
    "import gymnasium as gym\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "\n",
    "# Importing TQDM to track cell progress\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignoring Warnings\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5106b8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure to add .gitignore to temp_directory\n",
      "file already exist\n"
     ]
    }
   ],
   "source": [
    "# Importing Custom Code\n",
    "from MainCode.env import Simulator, Window, CustomTensorDataReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6497a0",
   "metadata": {},
   "source": [
    "# Initializing Custom Classes Built from Pre-processing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd543ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our class to read our numpy matrix files and merging them\n",
    "dr = CustomTensorDataReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our class to manage our environment Window\n",
    "# This is our login window (1 second time stamp)\n",
    "wd = Window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fac9bf",
   "metadata": {},
   "source": [
    "# Showing the shape of our data with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c86506e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62223, 1553, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 62223 Time Stamps\n",
    "# 1553 Logins for each time stamp (this includes padding entries with 0)\n",
    "# 17 items per login entry\n",
    "dr.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40186fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, info = wd.reset_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d241d0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1553, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d057e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.target_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e90aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29813"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.current_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1e33a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62223, 1553, 17)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how to access our data\n",
    "# This accesses the first login, represented by j, of our first time stamp, i\n",
    "# wd.data[i][j]\n",
    "wd.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45425c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14863575,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9446e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In\n"
     ]
    }
   ],
   "source": [
    "if (1 not in wd.target_data):\n",
    "    print('Not in')\n",
    "else:\n",
    "    print(\"In\")\n",
    "\n",
    "# if (np.any(wd.target_data, 1) == True):\n",
    "#     print('Got it')\n",
    "# else:\n",
    "#     print('damn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a18ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "05a6ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkEnv(Env):\n",
    "    def __init__(self):\n",
    "        # Actions we can take: We can Flag an item, Continue to the next item, or Finish/Hold once we have analyzed the current log/activity\n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "        # Time Stamp Login Array\n",
    "        self.observation_space = Box(low= np.array([0]), high = np.array([1552]), dtype=int)\n",
    "        \n",
    "        # Set Starting Login Entry\n",
    "        self.state = random.randint(0,1552)\n",
    "        \n",
    "        # Set Network Log Length\n",
    "        self.log_length = 1553\n",
    "        \n",
    "#         # Set Network Health\n",
    "        self.network_health = 100\n",
    "\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Apply Actions\n",
    "        # -1 If we have run out of items in the list we want to declare that we are finished OR if we are in a live environment we want to hold until our next activity\n",
    "        # 0 If we flag the item we want to perform an action before we continue OR if we are holding we want to flag when we start\n",
    "        # 1 If we don't detect abnormal behavior we want to continue to process the next item in the list\n",
    "        self.state += action\n",
    "        \n",
    "        # Decreamenting the length of our log by 1\n",
    "        self.log_length -= 1 \n",
    "        \n",
    "        # Calculating Reward\n",
    "        # Cases which our agent is correct\n",
    "        if (self.state == 1) and (1 in wd.target_window):\n",
    "            reward = 25 \n",
    "        elif (self.state == 0) and (1 not in wd.target_window):\n",
    "            reward = 25   \n",
    "        # Cases which our agent is incorrect    \n",
    "        elif (self.state == 1) and (1 not in wd.target_window):\n",
    "            reward = 50  \n",
    "        elif (self.state == 0) and (1 in wd. target_window):\n",
    "            reward = 50\n",
    "            self.network_health -= 25\n",
    "            \n",
    "        if self.log_length == 0 or self.network_health <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        # Placeholder for info\n",
    "        info = {}\n",
    "    \n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        # Reset our environment\n",
    "        self.state = random.randint(0,1552)\n",
    "        # Reset our log length\n",
    "        self.log_length = 1553\n",
    "        # Reset our network health\n",
    "        self.network_health = 100\n",
    "        \n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f634e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = NetworkEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ec0d25dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([830])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c2d7fb4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'reward' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m#env.render()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m---> 11\u001b[0m         n_state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#         network_health += health\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[112], line 50\u001b[0m, in \u001b[0;36mNetworkEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Placeholder for info\u001b[39;00m\n\u001b[0;32m     48\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[43mreward\u001b[49m, done, info\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'reward' referenced before assignment"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "#     network_health = 100\n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "#         network_health += health\n",
    "    print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866eba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (pytorch-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
